{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2020, Husnu Melih Erdogan\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Time Handwritten Digit Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hardware Requirements\n",
    "# - USB Webcam\n",
    "# - (Optional) CUDA supported graphics card\n",
    "# - This program needs about 400 MB RAM to run\n",
    "\n",
    "# Software Dependencies\n",
    "# - Python 3\n",
    "# - Anaconda (Optional)\n",
    "# - Jupyter Notebook (Optional)\n",
    "# - Pytorch\n",
    "# - OpenCv 3\n",
    "# - Numpy\n",
    "# - Matplotlib\n",
    "\n",
    "# Download the pre-trained model\n",
    "#  - Open a new terminal and go to the project directory\n",
    "#  - wget https://github.com/mlherd/Machine-Learning-Experiments/blob/master/RealTime_MNIST_CNN/cnn_model.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python Libraries\n",
    "\n",
    "# Image Processing\n",
    "import cv2\n",
    "\n",
    "# Machine Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import collections\n",
    "\n",
    "# Scientific Computing\n",
    "import numpy as np\n",
    "\n",
    "# Ploting\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model Class\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__ (self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        \n",
    "        # Layer 1 \n",
    "        # Convolution\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2)\n",
    "        # Activation\n",
    "        self.relu1 = nn.ReLU()\n",
    "        # Pooling \n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Layer 2\n",
    "        # Convolution\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        # Activation\n",
    "        self.relu2 = nn.ReLU()\n",
    "        # Pooling \n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Fully Connected Layer\n",
    "        # - 10 classes\n",
    "        # - 32 * 7 * 7 = 1568\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Layer 1\n",
    "        out1 = self.conv1(x)\n",
    "        out1 = self.relu1(out1)\n",
    "        out1 = self.maxpool1(out1)\n",
    "        \n",
    "        # Layer 2\n",
    "        out2 = self.conv2(out1)\n",
    "        out2 = self.relu2(out2)\n",
    "        out2 = self.maxpool2(out2)\n",
    "        \n",
    "        # Flattening\n",
    "        out3 = out2.view(out2.size(0), -1)\n",
    "        \n",
    "        # Fully Connected\n",
    "        out4 = self.fc1(out3)\n",
    "        \n",
    "        return out4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initilize the model by creating a model object using the CNNModel Class\n",
    "model = CNNModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pre-trained Model\n",
    "model.load_state_dict(torch.load(\"cnn_model.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide if we want to use CUDA\n",
    "# 1 = Use CUDA, 0 = Use CPU\n",
    "use_cuda = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the model to GPU if use_cuda = 1 and CUDA is available\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crerate a capture object using the VideoCapture constructor\n",
    "# Use camera 0 (Camera id number= 0)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    # Capture images frame by frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Convert BGR image to Grayscale\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Size of the ROI (Region Of Interest)\n",
    "    w = 100\n",
    "    h = 100\n",
    "    \n",
    "    # Center of the captured image\n",
    "    x = int(img.shape[1]/2)\n",
    "    y = int(img.shape[0]/2)\n",
    "    \n",
    "    # Left-upper corner (a,b) and right-lower corner (c,d) pixel locations of the ROI\n",
    "    a = int(x-(w/2))\n",
    "    b = int(y-(h/2))\n",
    "    c = int(x+w/2)\n",
    "    d = int(y+h/2)\n",
    "    \n",
    "    # Create points the rectangle drawing\n",
    "    start_point = (a, b)\n",
    "    end_point = (c, d)\n",
    "    \n",
    "    # Draw a rectangle\n",
    "    img_rect = img.copy();\n",
    "    cv2.rectangle(frame, start_point, end_point, (0,0,255), thickness=2)\n",
    "    \n",
    "    # Crop the ROI\n",
    "    img_crop = img[b:d,a:c]\n",
    "    cv2.imshow('Cropped 100x100', img_crop)\n",
    "    \n",
    "    # Normalize the Image 255-0 -> 1-0\n",
    "    # Invert the Colors 0->1 1->0\n",
    "    img_normalized = img_crop/255\n",
    "    img_inverted = (img_normalized-1)*-1\n",
    "    cv2.imshow('Normalize + Invert', img_inverted)\n",
    "    \n",
    "    # Dilate the Image because pen written number is small\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    img_dilated = cv2.dilate(img_inverted,kernel,iterations = 1)\n",
    "    cv2.imshow('Dilate', img_dilated)\n",
    "    \n",
    "    # Resize the image to the size CNN uses 28x28\n",
    "    img_resized = cv2.resize(img_dilated, (28, 28))\n",
    "    cv2.imshow('28x28', img_resized)\n",
    "    \n",
    "    # Use closing to reduce the noise and artifects after resizing\n",
    "    kernel = np.ones((2,2),np.uint8)\n",
    "    img_closing = cv2.morphologyEx(img_resized, cv2.MORPH_CLOSE, kernel)\n",
    "    cv2.imshow('Closing', img_closing)\n",
    "    \n",
    "    # Conver the image to binary image. Black and white pixels only\n",
    "    ret,img_final = cv2.threshold(img_closing,0.5,1.0,cv2.THRESH_BINARY)\n",
    "    cv2.imshow('Final', img_final)\n",
    "    \n",
    "    # Reshape the image for the CNN\n",
    "    img_ready = img_final.reshape(1,1,28,28)\n",
    "    img_ready = img_ready.copy()\n",
    "    \n",
    "    # Make the image a Pytorch variable\n",
    "    # Move the Variable to GPU if use_cuda = 1 and CUDA is available\n",
    "    img_ready = torch.from_numpy(img_ready).float()\n",
    "    if torch.cuda.is_available() and use_cuda:\n",
    "        img_ready = Variable(img_ready.cuda())\n",
    "    else:\n",
    "        img_ready = Variable(img_ready)\n",
    "    \n",
    "    # Get all the predictions\n",
    "    predictions = model(img_ready)\n",
    "    \n",
    "    # Use the largest one as the final prediction\n",
    "    _, predictions = torch.max(predictions.data, 1)\n",
    "    text = str(predictions.cpu().numpy()[0])\n",
    "    \n",
    "    # Write the predicted class in the image\n",
    "    cv2.putText(frame, text=text, org=(a-10,b-10), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(0,0,255), thickness=2, lineType=cv2.LINE_AA)\n",
    "    cv2.imshow('main', frame)\n",
    "    \n",
    "    # If q is pressed quit the program\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Close all the windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
